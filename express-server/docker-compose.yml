# ============================================
# Enterprise Workflow Management System
# Docker Compose - Production Configuration
# ============================================

version: '3.9'

services:
  # ============================================
  # INFRASTRUCTURE SERVICES
  # ============================================
  
  postgres:
    image: postgres:16-alpine
    container_name: workflow-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-workflow_admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_MULTIPLE_DATABASES: auth_db,user_db,permission_db,workflow_def_db,workflow_inst_db,task_db,approval_db,document_db,audit_db,notification_db,reporting_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./infrastructure/docker/postgres/init-databases.sh:/docker-entrypoint-initdb.d/init-databases.sh
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-workflow_admin}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - workflow-network

  redis:
    image: redis:7-alpine
    container_name: workflow-redis
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - workflow-network

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: workflow-zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_log:/var/lib/zookeeper/log
    networks:
      - workflow-network

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: workflow-kafka
    restart: unless-stopped
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - workflow-network

  # ============================================
  # OBSERVABILITY STACK
  # ============================================
  
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: workflow-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
    volumes:
      - ./infrastructure/kubernetes/monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - workflow-network

  grafana:
    image: grafana/grafana:10.2.0
    container_name: workflow-grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infrastructure/kubernetes/monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
    ports:
      - "3100:3000"
    depends_on:
      - prometheus
    networks:
      - workflow-network

  jaeger:
    image: jaegertracing/all-in-one:1.51
    container_name: workflow-jaeger
    restart: unless-stopped
    environment:
      COLLECTOR_ZIPKIN_HOST_PORT: 9411
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686"
      - "14268:14268"
      - "14250:14250"
      - "9411:9411"
    networks:
      - workflow-network

  # ============================================
  # API GATEWAY
  # ============================================
  
  api-gateway:
    build:
      context: ./api-gateway
      dockerfile: Dockerfile
    container_name: workflow-api-gateway
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3000
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      AUTH_SERVICE_URL: http://auth-service:3001
      USER_SERVICE_URL: http://user-service:3002
      PERMISSION_SERVICE_URL: http://permission-service:3003
      WORKFLOW_DEFINITION_SERVICE_URL: http://workflow-definition-service:3004
      WORKFLOW_INSTANCE_SERVICE_URL: http://workflow-instance-service:3005
      TASK_SERVICE_URL: http://task-service:3006
      APPROVAL_SERVICE_URL: http://approval-service:3007
      DOCUMENT_SERVICE_URL: http://document-service:3008
      AUDIT_SERVICE_URL: http://audit-service:3009
      NOTIFICATION_SERVICE_URL: http://notification-service:3010
      REPORTING_SERVICE_URL: http://reporting-service:3011
    ports:
      - "3000:3000"
    depends_on:
      - redis
      - kafka
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - workflow-network

  # ============================================
  # MICROSERVICES
  # ============================================
  
  auth-service:
    build:
      context: ./services/auth-service
      dockerfile: Dockerfile
    container_name: workflow-auth-service
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3001
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/auth_db
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      KAFKA_BROKERS: kafka:29092
      JWT_ACCESS_SECRET: ${JWT_ACCESS_SECRET}
      JWT_REFRESH_SECRET: ${JWT_REFRESH_SECRET}
    depends_on:
      - postgres
      - redis
      - kafka
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - workflow-network

  user-service:
    build:
      context: ./services/user-service
      dockerfile: Dockerfile
    container_name: workflow-user-service
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3002
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/user_db
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      KAFKA_BROKERS: kafka:29092
    depends_on:
      - postgres
      - redis
      - kafka
    networks:
      - workflow-network

  permission-service:
    build:
      context: ./services/permission-service
      dockerfile: Dockerfile
    container_name: workflow-permission-service
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3003
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/permission_db
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      KAFKA_BROKERS: kafka:29092
    depends_on:
      - postgres
      - redis
      - kafka
    networks:
      - workflow-network

  workflow-definition-service:
    build:
      context: ./services/workflow-definition-service
      dockerfile: Dockerfile
    container_name: workflow-definition-service
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3004
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/workflow_def_db
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      KAFKA_BROKERS: kafka:29092
    depends_on:
      - postgres
      - redis
      - kafka
    networks:
      - workflow-network

  workflow-instance-service:
    build:
      context: ./services/workflow-instance-service
      dockerfile: Dockerfile
    container_name: workflow-instance-service
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3005
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/workflow_inst_db
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      KAFKA_BROKERS: kafka:29092
    depends_on:
      - postgres
      - redis
      - kafka
    networks:
      - workflow-network

  task-service:
    build:
      context: ./services/task-service
      dockerfile: Dockerfile
    container_name: workflow-task-service
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3006
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/task_db
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      KAFKA_BROKERS: kafka:29092
    depends_on:
      - postgres
      - redis
      - kafka
    networks:
      - workflow-network

  approval-service:
    build:
      context: ./services/approval-service
      dockerfile: Dockerfile
    container_name: workflow-approval-service
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3007
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/approval_db
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      KAFKA_BROKERS: kafka:29092
    depends_on:
      - postgres
      - redis
      - kafka
    networks:
      - workflow-network

  document-service:
    build:
      context: ./services/document-service
      dockerfile: Dockerfile
    container_name: workflow-document-service
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3008
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/document_db
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      KAFKA_BROKERS: kafka:29092
      S3_ENDPOINT: ${S3_ENDPOINT}
      S3_ACCESS_KEY: ${S3_ACCESS_KEY}
      S3_SECRET_KEY: ${S3_SECRET_KEY}
      S3_BUCKET: ${S3_BUCKET}
    depends_on:
      - postgres
      - redis
      - kafka
    networks:
      - workflow-network

  audit-service:
    build:
      context: ./services/audit-service
      dockerfile: Dockerfile
    container_name: workflow-audit-service
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3009
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/audit_db
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      KAFKA_BROKERS: kafka:29092
    depends_on:
      - postgres
      - redis
      - kafka
    networks:
      - workflow-network

  notification-service:
    build:
      context: ./services/notification-service
      dockerfile: Dockerfile
    container_name: workflow-notification-service
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3010
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/notification_db
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      KAFKA_BROKERS: kafka:29092
      SMTP_HOST: ${SMTP_HOST}
      SMTP_PORT: ${SMTP_PORT}
      SMTP_USER: ${SMTP_USER}
      SMTP_PASSWORD: ${SMTP_PASSWORD}
    depends_on:
      - postgres
      - redis
      - kafka
    networks:
      - workflow-network

  reporting-service:
    build:
      context: ./services/reporting-service
      dockerfile: Dockerfile
    container_name: workflow-reporting-service
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3011
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/reporting_db
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      KAFKA_BROKERS: kafka:29092
    depends_on:
      - postgres
      - redis
      - kafka
    networks:
      - workflow-network

# ============================================
# VOLUMES
# ============================================
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_log:
    driver: local
  kafka_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

# ============================================
# NETWORKS
# ============================================
networks:
  workflow-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16
